<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="【笔记】机器学习安全及隐私保护研究进展敌手模型： ​    -敌手目标： ​    （1）破坏机密性：敌手窃取含有敏感信息的训练数据，通过暴露目标模型信息及其预测结果达到目的。（2）完整性威胁是指敌手诱导模型行为或者使模型在预测中输出指定分类标签。（3）可用性威胁指阻止用户获得模型正确输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖。 ​    -敌手知识： ​    敌手知识包括模型">
<meta name="keywords" content="机器学习安全，隐私">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习安全及隐私保护的研究进展">
<meta property="og:url" content="http://yoursite.com/2019/09/05/【笔记】机器学习安全及隐私保护研究进展/index.html">
<meta property="og:site_name" content="Jkq&#39;s Personal Blog">
<meta property="og:description" content="【笔记】机器学习安全及隐私保护研究进展敌手模型： ​    -敌手目标： ​    （1）破坏机密性：敌手窃取含有敏感信息的训练数据，通过暴露目标模型信息及其预测结果达到目的。（2）完整性威胁是指敌手诱导模型行为或者使模型在预测中输出指定分类标签。（3）可用性威胁指阻止用户获得模型正确输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖。 ​    -敌手知识： ​    敌手知识包括模型">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-09-08T03:58:00.204Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习安全及隐私保护的研究进展">
<meta name="twitter:description" content="【笔记】机器学习安全及隐私保护研究进展敌手模型： ​    -敌手目标： ​    （1）破坏机密性：敌手窃取含有敏感信息的训练数据，通过暴露目标模型信息及其预测结果达到目的。（2）完整性威胁是指敌手诱导模型行为或者使模型在预测中输出指定分类标签。（3）可用性威胁指阻止用户获得模型正确输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖。 ​    -敌手知识： ​    敌手知识包括模型">
  <link rel="canonical" href="http://yoursite.com/2019/09/05/【笔记】机器学习安全及隐私保护研究进展/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>机器学习安全及隐私保护的研究进展 | Jkq's Personal Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jkq's Personal Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/05/【笔记】机器学习安全及隐私保护研究进展/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jkq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jkq's Personal Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">机器学习安全及隐私保护的研究进展

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-05 20:58:26" itemprop="dateCreated datePublished" datetime="2019-09-05T20:58:26+08:00">2019-09-05</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-08 11:58:00" itemprop="dateModified" datetime="2019-09-08T11:58:00+08:00">2019-09-08</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="【笔记】机器学习安全及隐私保护研究进展"><a href="#【笔记】机器学习安全及隐私保护研究进展" class="headerlink" title="【笔记】机器学习安全及隐私保护研究进展"></a>【笔记】机器学习安全及隐私保护研究进展</h1><p><strong>敌手模型：</strong></p>
<p>​    -敌手目标：</p>
<p>​    （1）破坏机密性：敌手窃取含有敏感信息的训练数据，通过暴露目标模型信息及其预测结果达到目的。（2）完整性威胁是指敌手诱导模型行为或者使模型在预测中输出指定分类标签。（3）可用性威胁指阻止用户获得模型正确输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖。</p>
<p>​    -敌手知识：</p>
<p>​    敌手知识包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模 型得到反馈信息等。根据敌手已知信息的多少， 敌手知识分为有限知识和完全知识。在预测阶段中，根据敌手知识可将攻击分为白盒攻击和黑盒攻击。白盒攻击指敌手得到目标模型，了解模型的内部结构及其参数。黑盒攻击指敌手只能访问目标模型，根据输入数据得到模型输出相应的预测结果。在实际中，白盒攻击不易实现，黑盒攻击更为常见。 </p>
<a id="more"></a>
<p>​    -敌手能力：</p>
<p>​    指敌手在拥有一定知识背景下，对模型或者训练数据，测试数据的控制能力。根据控制能力的不同，可以分为弱敌手和强敌手。在训练阶段中，敌手访问训练数据，注入恶意数据，直接修改数据，敌手能力逐渐增强。在预测阶段，白盒攻击的敌手能力比黑盒攻击强。</p>
<p>​    -敌手策略：</p>
<p>​    指敌手为达到攻击目标， 根据自身的知识和能力，采取的具体攻击方式， 如修改数据集标签信息、注入恶意数据、逆向攻 击提取敏感数据等。 </p>
<p>目的模型的有效性依赖于训练数据集和预测数据集属于同一分布，例如预测数据和训练数据分布存在差异，那么实际预测阶段就会出现偏差。</p>
<p><strong>训练阶段威胁</strong></p>
<p>​    <strong>-投毒攻击（poisoning attack）：</strong></p>
<p>​    敌手对训练数据进行修改，删除或者注入精心制作的恶意数据，改变训练数据的原有分布，使得学习算法的逻辑发生改变，而目标模型发生改变。</p>
<p>​    文献[6-7]。 敌手通过注入精心制作的恶意样本改变训练样本 的分布，训练后模型的决策边界发生变化，使预 测阶段模型的精度降低，甚至敌手可以诱导模型 输出指定的错误分类标签。</p>
<p><strong>预测阶段威胁</strong></p>
<p>​    <strong>-对抗样本攻击：</strong></p>
<p>​    又细分为白盒攻击和黑盒攻击。</p>
<p>​    白盒攻击转为优化问题：$arg\ min_r \ h(x+r)= l \ s.t \in D$，即$x$为输入，$r$是加的扰动，希望能在输入上加一个尽可能小的扰动就让模型预测时将$x*$错误分类到$l$标签下。</p>
<p>​    黑盒攻击(oracle attack)：通过API访问目标模型，观察特定输入对应的输出信息。</p>
<p>​    Oracle 攻击的有效性 与询问目标模型的输入及查询次数密切相关。 Lowd 等[19]评估了使模型错分类需要询问次数的成本</p>
<p><strong>防御手段：</strong></p>
<p>​    正则化（regularization）。通过为代价函数 添加正则项（也叫惩罚项）提高目标模型的泛 化能力，在预测中遇见未知数据集具有良好的适应性抵抗攻击。</p>
<p>​    对抗训练（adversarial training）。在训练数据 集中引入对抗样本，通过合法化的对抗样本对目 标模型的训练提供模型的顽健性。Tramèr 等[29]提出 联合对抗训练（ensemble adversarial training）增加对抗样本多样性，但在对抗训练中引入所有未 知攻击的对抗样本是不现实的，对抗训练的非适应性导致对抗训练的局限性。 </p>
<p>​    防御精馏（defensive distillation）。2016 年， Papernot 等[30]在 distillation[31]技术的基础上提出 防御精馏技术抵抗攻击。原 distillation 技术旨在 将大规模模型压缩为小规模并保留原有的准确 性，而 defensive distillation 不改变模型规模的大 小，产生输出表面更平滑的、对扰动不敏感的模 型提高模型的顽健性</p>
<p>​    文献[36-37]先检测预测样本是否为合法样本，若为合法样本则进行预测，若为对抗样本 则直接丢弃，在抵御对抗攻击取得一定效果。 </p>
<p><strong>机器学习中的隐私保护</strong></p>
<pre><code> 训练阶段：窃取训练数据
</code></pre><p>​    预测阶段：逆向攻击和成员推理攻击</p>
<p>为了扩大训练数据集得到精确的 目标模型，一些数据提供方需要进行协作“分享” 数据，共同训练目标模型。“分享”不是直接对其 他参与方公开数据，各个参与方独自在各自数据 集上训练自己的模型，与其他参与方共享训练结 果，从而间接分享各自的训练数据。联合训练 模型易受不诚实的参与方攻击，恶意窃取其他 参与者数据。Hitaj 等[38]利用生成对抗网络（GAN, generative adversarial networks)，对联合分布式训 练深度学习模型发起攻击，任意参加训练的用户都可能成为敌手，生成与其他参与者训练数据无 限逼近的假样本来窃取他人隐私。</p>
<p><strong>基于同态加密的机器学习隐私保护技术：</strong></p>
<p>​    同态加密只支持乘法和加法运算。</p>
<p>​    使用同态加密技术对机器学习进行隐私保护，可以在预测阶段中对加密数据直接进行预测， 预测结果也是密文，将结果返回给用户自行解密来保护用户数据隐私</p>
<p>​    利用加密技术保护机器学习用户敏感 数据多用于预测阶段，虽然在训练阶段中理论上 可行，但是深度学习本来就大量消耗计算资源， 加密技术计算开销大，网络训练过程慢。如将复 杂计算交给云端处理，需注意神经网络模型训练 过程是一个迭代的过程，随着运算次数的增多， 同态计算电路深度加深，一旦超过阈值，将无法 解密得到正确的计算结果。同时也要考虑客户端 和云端通信等问题。 </p>
<p><strong>基于差分隐私的机器学习隐私保护技术：</strong></p>
<p>​    在集中式学习中，为保护敏感训练数据，2016 年，Abadi 等[52]提出基于差分隐私的深度学习算 法，利用随机梯度下降过程中对梯度增加扰动来 保护训练敏感数据，并在差分隐私框架下对隐私 成本进行了精细的分析，经实验证明，可以在隐 私成本可控的情况下完成深层网络训练</p>
<p>​    2017 年，Papernot 等[53]提出用半监督知识迁移解决深 度学习中训练数据隐私泄露问题，通过教师模型 全体的隐私聚合（PATE, private aggregation of teacher ensembles）为训练数据提供通用的强健隐 私保护。作者将敏感数据分割成 N 个不相交的数 据集，在每个数据集上独立训练得到 N 个教师模 型，通过对投票引入噪声，算出得票高的预测 结果。然后用公开不含标签的数据集（利用教师 模型标注）训练学生模型进行知识迁移传递， 终部署学生模型进行预测服务。</p>
<p>​    不使用敏感数据 直接训练公开模型，防止逆向攻击提取原始敏感 数据。Beaulieujones 等[54]利用文献[52]中方法， 提出差分隐私辅助分类生成对抗网络生成医疗临 床数据。郭鹏等[55]对文献[54]提出改进，实现对 生成对抗网络进行差分隐私保护。</p>
<p>​    2015 年，Shokri 和 Shmatikov[56]首次将隐私保护概念引入深度学习 中，提出保护隐私的联合分布式深度学习方案， 并且提供差分隐私保障。每个参与训练人员将本 地的一小部分梯度参数引入噪声后上传到中心参 数服务器端，每次更新本地参数时从服务器下载 部分新的梯度参数进行更新，使参与者在不公 开自己数据集的情况下，从其他参与者中获益。 </p>
<p>​    </p>
<p>​    2017年，Google推出联合学习[59-60]， Android 设备从 Google 服务器上下载模型，通过 本地数据训练进行更新改进。与文献[56]不同的是， Google 并没有采用差分隐私技术，而是建议使用更 安全的聚合协议安全多方计算（MPC），利用联合 平均算法（federated averaging algorithm）[60-61]计 算各个用户设备的更新，但 Google 服务器只有在 多个用户参与时才能解密更新模型。Osia 等[62]提出 一种用于隐私保护的移动分析混合深度学习架构。 首次将孪生神经网络用于隐私保护的深度学习中， 利用本地移动资源（如智能手机）提取敏感数据特 征（预处理），再送入云端进行预测。既使用云端 高效的资源，又避免直接暴露自身的敏感数据</p>
<p>[1] GHORBEL A, GHORBEL M, JMAIEL M. Privacy in cloud computing environments: a survey and research challenges[J]. Journal<br>of Supercomputing, 2017, 73(6):2763-2800. </p>
<p>[2] SILVER D, HUANG A, MADDISON C J, et al. Mastering the game of go with deep neural networks and tree search[J]. Nature, 2016, 529(7587): 484-489. </p>
<p>[3] BARRENO M, NELSON B, SEARS R, et al. Can machine learning be secure?[C]//ACM Symposium on Information, Computer and Communications Security. 2006:16-25. </p>
<p>[4] KEARNS M, LI M. Learning in the presence of malicious errors[J]. SIAM Journal on Computing, 1993, 22(4): 807-837.</p>
<p> [5] BIGGIO B, NELSON B, LASKOV P. Support vector machines under adversarial label noise[J]. Journal of Machine Learning Research, 2011, 20(3):97-112. </p>
<p>[6] BIGGIO B, NELSON B, LASKOV P. Poisoning attacks against support vector machines[C]//International Coference on International Conference on Machine Learning. 2012: 1467-1474. </p>
<p>[7] MEI S, ZHU X. Using machine teaching to identify optimal training-set attacks on machine learners[C]//AAAI. 2015: 2871-2877.</p>
<p> [8] BIGGIO B, DIDACI L, FUMERA G, et al. Poisoning attacks to compromise face templates[C]//International Conference on Biometrics. 2013: 1-7. </p>
<p>[9] KLOFT M, LASKOV P. Security analysis of online anomaly detection[J]. Journal of Machine Learning Research, 2010, 13(1): 3681-3724. </p>
<p>[10] C. SZEGEDY, W. ZAREMBA, I. SUTSKEVER, et al. Intriguing properties of neural networks[C]//2014 International Conference on Learning Representations. Computational and Biological Learning Society. 2014. </p>
<p>[11] PAPERNOT N, MC D P, SINHA A, et al. Towards the science of security and privacy in machine learning[J]. arXiv preprint arXiv: 1611.03814, 2016. </p>
<p>[12] GOODFELLOW I J, SHLENS J, SZEGEDY C. Explaining and harnessing adversarial examples[C]//International Conference on Learning Representations. 2015. </p>
<p>[13] KURAKIN A, GOODFELLOW I, BENGIO S. Adversarial machine learning at scale[J]. arXiv preprint arXiv:1611.01236, 2017.</p>
<p> [14] DONG Y P, LIAO F Z, PANG T Y, et al. Boosting adversarial attacks with momentum[J]. arXiv preprint arXiv:1710.06081, 2017.</p>
<p> [15] MIYATO T, MAEDA S, KOYAMA M, et al. Virtual adversarial training: a regularization method for supervised and semi-supervised learning[J]. arXiv preprint 1704.03976, 2017.</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/机器学习安全，隐私/" rel="tag"># 机器学习安全，隐私</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/09/05/【笔记】机器学习安全性问题及其防御技术研究综述/" rel="next" title="机器学习安全性的一些问题">
                  <i class="fa fa-chevron-left"></i> 机器学习安全性的一些问题
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/09/05/【笔记】差分隐私保护的机器学习/" rel="prev" title="差分隐私保护下的机器学习">
                  差分隐私保护下的机器学习 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#【笔记】机器学习安全及隐私保护研究进展"><span class="nav-number">1.</span> <span class="nav-text">【笔记】机器学习安全及隐私保护研究进展</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jkq</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
        
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jkq</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/muse.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
